---
# Default values for purelb.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Docker image configuration
image:
  repository: DEFAULT_REPO
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: DEFAULT_TAG

nameOverride: ""
fullnameOverride: ""

Prometheus:
  allocator:
    # Metrics service
    Metrics:
      enabled: false

    ## ServiceMonitor
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md
    ## Note: requires Prometheus Operator to be able to work, for example:
    ## helm install prometheus prometheus-community/kube-prometheus-stack \
    ##   --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false \
    ##   --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false
    serviceMonitor:
      ## Toggle the ServiceMonitor true if you have Prometheus Operator installed and configured
      enabled: false

      ## Specify the labels to add to the ServiceMonitors to be selected for target discovery
      extraLabels: {}

      ## Specify the endpoints
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/design.md#servicemonitor
      endpoints: []
      ## Sample
      ## endpoints:
      ## - port: metrics
      ##   path: /metrics
      ##   scheme: http
    prometheusRules:
      ## Toggle the prometheusRules to true if you have Prometheus Operator installed and configured
      ##
      enabled: false
      ## Specify the namespace where to add to the prometheusRules
      ##
      namespace: ""
      ## Specify the labels to add to the prometheusRules to be selected for target discovery
      extraLabels: {}
      ## Define here the Custom Prometheus rules
      ## e.g:
      ## rules:
      ##   - alert: PurelbServiceGroupHigh
      ##     expr: purelb_address_pool_addresses_in_use * 100 / purelb_address_pool_size > 90
      ##     for: 2m
      ##     labels:
      ##       severity: critical
      ##     annotations:
      ##       summary: PureLB allocator {{`{{`}} $labels.instance {{`}}`}} as high usage of pool
      ##       description: PureLB allocator {{`{{`}} $labels.instance {{`}}`}} as high usage of pool
      rules: []

  lbnodeagent:
    # Metrics service
    Metrics:
      enabled: false

    ## ServiceMonitor
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md
    ## Note: requires Prometheus Operator to be able to work, for example:
    ## helm install prometheus prometheus-community/kube-prometheus-stack \
    ##   --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false \
    ##   --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false
    serviceMonitor:
      ## Toggle the ServiceMonitor true if you have Prometheus Operator installed and configured
      enabled: false

      ## Specify the labels to add to the ServiceMonitors to be selected for target discovery
      extraLabels: {}

      ## Specify the endpoints
      ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/design.md#servicemonitor
      endpoints: []
      ## Sample
      ## endpoints:
      ## - port: metrics
      ##   path: /metrics
      ##   scheme: http
    prometheusRules:
      ## Toggle the prometheusRules true if you have Prometheus Operator installed and configured
      ##
      enabled: false
      ## Specify the namespace where to add to the prometheusRules
      ##
      namespace: ""
      ## Specify the labels to add to the prometheusRules to be selected for target discovery
      extraLabels: {}
      ## Define here the Custom Prometheus rules
      ## e.g:
      ## rules:
      ##   - alert: PurelbServiceGroupHigh
      ##     expr: purelb_address_pool_addresses_in_use * 100 / purelb_address_pool_size > 90
      ##     for: 2m
      ##     labels:
      ##       severity: critical
      ##     annotations:
      ##       summary: PureLB instance {{ "{{ $labels.instance }}" }} down
      ##       description: Redis&trade; instance {{ "{{ $labels.instance }}" }} is down
      rules: []

# You may define a valid spec and set create: true to create a ServiceGroup.
# See https://purelb.github.io/purelb/install/config/
serviceGroup:
  name: "default"
  create: false
  # Single-stack example:
  # create: true
  # spec:
  #   local:
  #     v4pool:
  #       subnet: '192.168.254.0/24'
  #       pool: '192.168.254.200-192.168.254.210'
  #       aggregation: default
  #
  # Dual-stack example:
  # create: true
  # spec:
  #   local:
  #     v4pool:
  #       subnet: '192.168.254.0/24'
  #       pool: '192.168.254.200-192.168.254.210'
  #       aggregation: default
  #     v6pool:
  #       subnet: 'fd53:9ef0:8683::/120'
  #       pool: 'fd53:9ef0:8683::1-fd53:9ef0:8683::10'
  #       aggregation: default

# This can be used to define a list of arbitrary extra Kubernetes objects to be created (configmaps, serviceGroups, etc.).
# Example:
#   extraObjects:
#     - |
#       apiVersion: v1
#       kind: ConfigMap
#       metadata:
#         name: {{ .Release.Name }}-extra
#       data:
#         hello: world
#     - |
#       apiVersion: purelb.io/v1
#       kind: ServiceGroup
#       metadata:
#         name: private
#       spec:
#         local:
#           pool: 192.168.0.0-192.168.0.5
#           subnet: 192.168.0.0/27
extraObjects: []

# PureLB will act as the default service announcer if this value is
# "PureLB". This means that PureLB will handle services that do not
# have a Spec.LoadBalancerClass field. If this is other than "PureLB"
# then PureLB will handle only those services that have a
# Spec.LoadBalancerClass explictly set to "purelb.io/purelb".
defaultAnnouncer: "PureLB"

# DEPRECATED: memberlistSecretKey is no longer used.
# PureLB now uses Kubernetes Leases for leader election instead of memberlist.
# This value is kept for backward compatibility but has no effect.
# It will be removed in a future release.
memberlistSecretKey: "8sb7ikA5qHwQQqxc"

# Optional priorityClass to use for both allocator and lbnodeagent pods.
# https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/
priorityClassName: ""

# Lease-based leader election configuration.
# These control how lbnodeagent nodes coordinate to elect winners for
# announcing service addresses. The defaults work well for most deployments.
leaseConfig:
  # How long a lease is valid before it expires
  leaseDuration: "10s"
  # How long to retry renewals before giving up
  renewDeadline: "7s"
  # Interval between renewal attempts
  retryPeriod: "2s"

# Configurable values specific to lbnodeagent.
# See https://purelb.github.io/purelb/install/config/
lbnodeagent:
  localint: default
  extlbint: kube-lb0
  sendgarp: false
  # Address configuration to prevent CNI conflicts (e.g., Flannel).
  # Configure how VIP addresses are added to interfaces.
  # addressConfig:
  #   localInterface:
  #     validLifetime: 300      # seconds, 0 = permanent (default: 300)
  #     preferredLifetime: 300  # must be <= validLifetime
  #     noPrefixRoute: true     # prevent kernel prefix route (default: true)
  #   dummyInterface:
  #     validLifetime: 0        # permanent for dummy interface (default: 0)
  #     noPrefixRoute: false    # (default: false)
  addressConfig: {}
  containerSecurityContext:
    runAsUser: 0
    runAsGroup: 0
    allowPrivilegeEscalation: false
    capabilities:
      add:
      - NET_ADMIN
      - NET_RAW
      drop:
      - ALL
    readOnlyRootFilesystem: false
    seccompProfile:
      type: RuntimeDefault
  # Tolerations: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # For example, to allow lbnodeagents to run on master nodes, comment the above line and uncomment the following lines:
  # tolerations:
  # - effect: NoSchedule
  #   key: node-role.kubernetes.io/master
  # nodeSelector: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
  nodeSelector:
  # For example, run lbnodeagent only on nodes with a specific label:
  # nodeSelector:
  #   some.example/label: "value"


# Configurable values specific to allocator.
allocator:
  # Set the container security context
  containerSecurityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - all
    readOnlyRootFilesystem: true
    seccompProfile:
      type: RuntimeDefault
  # Tolerations: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # For example, to allow the allocator to run on master nodes, comment the above line and uncomment the following lines:
  # tolerations:
  # - effect: NoSchedule
  #   key: node-role.kubernetes.io/master

  # Set the pod security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 65534
    seccompProfile:
      type: RuntimeDefault
